{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Azure OpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from collections import Counter\n",
    "from bertopic import BERTopic\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from https://towardsdatascience.com/topic-modelling-using-chatgpt-api-8775b0891d16\n",
    "import tiktoken \n",
    "import pandas as pd\n",
    "gpt4_enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "def get_tokens(enc, text):\n",
    "    return list(map(lambda x: enc.decode_single_token_bytes(x).decode('utf-8'), \n",
    "                  enc.encode(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "# setting up APIKey to access ChatGPT API\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY'] \n",
    "\n",
    "\n",
    "# simple function that return just model response\n",
    "def get_model_response(messages, \n",
    "                       model = 'gpt-3.5-turbo', \n",
    "                       temperature = 0, \n",
    "                       max_tokens = 1000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "\n",
    "# we can also return token counts\n",
    "def get_model_response_with_token_counts(messages, \n",
    "                                   model = 'gpt-3.5-turbo', \n",
    "                                   temperature = 0, \n",
    "                                   max_tokens = 1000):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message['content']\n",
    "    \n",
    "    tokens_count = {\n",
    "      'prompt_tokens':response['usage']['prompt_tokens'],\n",
    "      'completion_tokens':response['usage']['completion_tokens'],\n",
    "      'total_tokens':response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, tokens_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv= \"data/\"\n",
    "\n",
    "df = pd.read_csv(path_csv+'transcriptions.csv')\n",
    "# Filter out videos with the same video_id\n",
    "df = df.drop_duplicates(subset=['video_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790\n"
     ]
    }
   ],
   "source": [
    "docs_classifier = [\n",
    "   str(df[\"video_description\"][a]) + \"\\n\\n\" +  str(df[\"suggested_words\"][a]) +\"\\n\\n\" +  str(df[\"german_transcript\"][a])\n",
    "    for a in df.index\n",
    "]\n",
    "\n",
    "docs = [str(df[\"german_transcript\"][a])\n",
    "    for a in df.index\n",
    "]\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_prompt = \"\"\"\n",
    "Ich habe ein Thema, das durch die folgenden Stichwörter beschrieben wird: [KEYWORDS]\n",
    "In diesem Thema sind die folgenden Dokumente eine kleine, aber repräsentative Untermenge aller Dokumente im Thema:\n",
    "[DOCUMENTS]\n",
    "\n",
    "Basierend auf den oben genannten Informationen geben Sie bitte eine Beschreibung dieses Themas in einer Aussage im folgenden Format ab:\n",
    "Thema:  <description>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_model= AzureChatOpenAI(\n",
    "    openai_api_version=\"2024-02-01\",\n",
    "    azure_deployment=\"gpt-35-turbo-16k\", chat=True, prompt=summarization_prompt, \n",
    "                              nr_docs=10, delay_in_seconds=3\n",
    ")\n",
    "\n",
    "embeddings_client = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"text-embedding-3-small-eastus\",\n",
    "    openai_api_version=\"2024-02-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stop_words= open(\"data/clustering/german_stopwords_full.txt\").read().split()[53:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(path_csv+\"/clustering/transcriptions.npy\")\n",
    "topic_model = BERTopic() #nr_topics = 50, embedding_model=embeddings_client\n",
    "topics, ini_probs = topic_model.fit_transform(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "      <td>-1_sie_fr_einfach_vaterland</td>\n",
       "      <td>[sie, fr, einfach, vaterland, hnden, unseren, ...</td>\n",
       "      <td>[einfach 1 bisschen schneller rausgehen. bleib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>603</td>\n",
       "      <td>0_die_und_der_das</td>\n",
       "      <td>[die, und, der, das, ich, ist, in, nicht, wir,...</td>\n",
       "      <td>[es ist eiskalter Kaffee, den sie jetzt wieder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1_die_und_das_in</td>\n",
       "      <td>[die, und, das, in, ja, der, auch, hier, mensc...</td>\n",
       "      <td>[tun Deutschland hat mit den Entscheidung für ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2_gestrichen_nicht_werden_prsent</td>\n",
       "      <td>[gestrichen, nicht, werden, prsent, wir, ersat...</td>\n",
       "      <td>[wenn diese beiden Maßnahmen nicht gestrichen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3_sie_unseris_wer_gelacht</td>\n",
       "      <td>[sie, unseris, wer, gelacht, hab, kaputt, gese...</td>\n",
       "      <td>[wer sind sie eigentlich? hab sie noch nie ges...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                              Name  \\\n",
       "0     -1     34       -1_sie_fr_einfach_vaterland   \n",
       "1      0    603                 0_die_und_der_das   \n",
       "2      1    125                  1_die_und_das_in   \n",
       "3      2     14  2_gestrichen_nicht_werden_prsent   \n",
       "4      3     14         3_sie_unseris_wer_gelacht   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [sie, fr, einfach, vaterland, hnden, unseren, ...   \n",
       "1  [die, und, der, das, ich, ist, in, nicht, wir,...   \n",
       "2  [die, und, das, in, ja, der, auch, hier, mensc...   \n",
       "3  [gestrichen, nicht, werden, prsent, wir, ersat...   \n",
       "4  [sie, unseris, wer, gelacht, hab, kaputt, gese...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [einfach 1 bisschen schneller rausgehen. bleib...  \n",
       "1  [es ist eiskalter Kaffee, den sie jetzt wieder...  \n",
       "2  [tun Deutschland hat mit den Entscheidung für ...  \n",
       "3  [wenn diese beiden Maßnahmen nicht gestrichen ...  \n",
       "4  [wer sind sie eigentlich? hab sie noch nie ges...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Topic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m repr_docs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_representative_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_tf_idf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_tf_idf_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mtopics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopic_representations_\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mnr_repr_docs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bertopic/_bertopic.py:3846\u001b[0m, in \u001b[0;36mBERTopic._extract_representative_docs\u001b[0;34m(self, c_tf_idf, documents, topics, nr_samples, nr_repr_docs, diversity)\u001b[0m\n\u001b[1;32m   3821\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Approximate most representative documents per topic by sampling\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;124;03ma subset of the documents in each topic and calculating which are\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m \u001b[38;5;124;03mmost represenative to their topic based on the cosine similarity between\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[38;5;124;03m                  that belong to each topic\u001b[39;00m\n\u001b[1;32m   3842\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3843\u001b[0m \u001b[38;5;66;03m# Sample documents per topic\u001b[39;00m\n\u001b[1;32m   3844\u001b[0m documents_per_topic \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3845\u001b[0m     \u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m-> 3846\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTopic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3847\u001b[0m              \u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mnr_samples, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m   3848\u001b[0m              \u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m   3849\u001b[0m )\n\u001b[1;32m   3851\u001b[0m \u001b[38;5;66;03m# Find and extract documents that are most similar to the topic\u001b[39;00m\n\u001b[1;32m   3852\u001b[0m repr_docs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Topic'"
     ]
    }
   ],
   "source": [
    "repr_docs, _, _ = topic_model._extract_representative_docs(c_tf_idf=topic_model.c_tf_idf_,\n",
    "                                                          documents=pd.DataFrame(docs),\n",
    "                                                          topics=topic_model.topic_representations_ ,\n",
    "                                                          nr_repr_docs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m delimiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m####\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m system_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mDu bist ein Experte im Schreiben. Du hilfst mir, einen gemeinsamen Titel für mehrere ähnliche TikTok-Beiträge zu schreiben. Der Titel sollte das gemeinsame Narrativ bestmöglichst beschreiben. Beispiele sind: Anti-Einwanderung: Grenzen schließen, nationale Identität schützen. Kritik am Establishment: Gegner des politischen Establishments, Alternativpartei. Kulturelle Identität: Betonung der deutschen Kultur, Traditionen bewahren. Anti-EU: Kritik an der EU, nationale Souveränität betonen. Forderung nach einer harte Hand gegen Kriminalität und Terrorismus. Hetzerischer Angriff und Kritik an Grünen ohne konstruktive Gegenvorschläge.\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      4\u001b[0m user_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mUntern findest du repräsentative TikTok Videos \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mBitte identifiziere die Hauptthemen, die in diesen Kommentaren erwähnt wurden.\u001b[39m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mGebe eine Liste von 10-20 Themen zurück.\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mDie Ausgabe ist eine JSON-Liste im folgenden Format:\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m[\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_name\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<topic1>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_description\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<topic_description1>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_name\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<topic2>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_description\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<topic_description2>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m    ...\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m]\u001b[39m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mTikTok Videos:\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepr_docs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     23\u001b[0m messages \u001b[38;5;241m=\u001b[39m  [  \n\u001b[1;32m     24\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     25\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: system_message},    \n\u001b[1;32m     26\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     27\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},  \n\u001b[1;32m     28\u001b[0m ] \n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "delimiter = '####'\n",
    "system_message = '''Du bist ein Experte im Schreiben. Du hilfst mir, einen gemeinsamen Titel für mehrere ähnliche TikTok-Beiträge zu schreiben. Der Titel sollte das gemeinsame Narrativ bestmöglichst beschreiben. Beispiele sind: Anti-Einwanderung: Grenzen schließen, nationale Identität schützen. Kritik am Establishment: Gegner des politischen Establishments, Alternativpartei. Kulturelle Identität: Betonung der deutschen Kultur, Traditionen bewahren. Anti-EU: Kritik an der EU, nationale Souveränität betonen. Forderung nach einer harte Hand gegen Kriminalität und Terrorismus. Hetzerischer Angriff und Kritik an Grünen ohne konstruktive Gegenvorschläge.\n",
    "'''\n",
    "user_message = f'''\n",
    "Untern findest du repräsentative TikTok Videos {delimiter}. \n",
    "Bitte identifiziere die Hauptthemen, die in diesen Kommentaren erwähnt wurden.\n",
    "\n",
    "Gebe eine Liste von 10-20 Themen zurück.\n",
    "Die Ausgabe ist eine JSON-Liste im folgenden Format:\n",
    "[\n",
    "    {{\"topic_name\": \"<topic1>\", \"topic_description\": \"<topic_description1>\"}}, \n",
    "    {{\"topic_name\": \"<topic2>\", \"topic_description\": \"<topic_description2>\"}},\n",
    "    ...\n",
    "]\n",
    "\n",
    "TikTok Videos:\n",
    "{delimiter}\n",
    "{delimiter.join(repr_docs)}\n",
    "{delimiter}\n",
    "'''\n",
    "\n",
    "\n",
    "messages =  [  \n",
    "        {'role':'system', \n",
    "         'content': system_message},    \n",
    "        {'role':'user', \n",
    "         'content': f\"{user_message}\"},  \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
